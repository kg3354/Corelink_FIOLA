
apiVersion: batch/v1
kind: Job
metadata:
  name: fiola-process-job
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: fiola-init-container
          image: registry.hsrn.nyu.edu/vip/corelink-examples/fiola-process-ns:latest
          command: ["sh", "-c"]
          args:
            - |
              python ./receive_then_fiola.py
              tail -f /dev/null
          resources:
            limits:
              nvidia.com/gpu: 1 # Limit 1 NVIDIA GPU    
              memory: "128Gi"
            requests:
              nvidia.com/gpu: 1 # Request 1 NVIDIA GPU
              memory: "128Gi"     
      nodeSelector:
        topology.kubernetes.io/zone: "meyer"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
  backoffLimit: 0