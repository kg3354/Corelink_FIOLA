# # # # apiVersion: batch/v1
# # # # kind: Job
# # # # metadata:
# # # #   name: fiola-process-job
# # # # spec:
# # # #   template:
# # # #     spec:
# # # #       restartPolicy: Never
# # # #       containers:
# # # #       - name: fiola-init-container
# # # #         image: registry.hsrn.nyu.edu/vip/corelink-examples/fiola-process:latest
# # # #         command: ["sh", "-c"]
# # # #         args:
# # # #           - |
# # # #             python ./receive_then_fiola.py
# # # #             tail -f /dev/null
# # # #         resources:
# # # #           limits:
# # # #             nvidia.com/gpu: 1 # Request 1 NVIDIA GPU
# # # #       tolerations:
# # # #       - key: nvidia.com/gpu
# # # #         operator: Exists
# # # #         effect: NoSchedule
# # # #   backoffLimit: 0


# # # apiVersion: batch/v1
# # # kind: Job
# # # metadata:
# # #   name: fiola-process-job
# # # spec:
# # #   template:
# # #     spec:
# # #       restartPolicy: Never
# # #       containers:
# # #         - name: fiola-init-container
# # #           image: registry.hsrn.nyu.edu/vip/corelink-examples/fiola-process-ns:latest
# # #           command: ["sh", "-c"]
# # #           args:
# # #             - |
# # #               python ./receive_then_fiola.py
# # #               tail -f /dev/null
# # #           resources:
# # #             limits:
# # #               nvidia.com/gpu: 2 # Limit 1 NVIDIA GPU
# # #               cpu: "10000m"          
# # #               memory: "128Gi"
# # #             requests:
# # #               nvidia.com/gpu: 2 # Request 1 NVIDIA GPU
# # #               cpu: "10000m"    
# # #               memory: "128Gi"     
# # #       nodeSelector:
# # #         topology.kubernetes.io/zone: "meyer"
# # #       tolerations:
# # #         - key: nvidia.com/gpu
# # #           operator: Exists
# # #           effect: NoSchedule
# # #   backoffLimit: 0
# # apiVersion: batch/v1
# # kind: Job
# # metadata:
# #   name: fiola-init-job
# # spec:
# #   template:
# #     spec:
# #       restartPolicy: Never
# #       containers:
# #         - name: fiola-init-container
# #           image: registry.hsrn.nyu.edu/vip/corelink-examples/fiola-init:latest #ns is the version without saving to disk.
# #           command: ["sh", "-c"]
# #           args:
# #             - |
# #               python3.8 ./generate_init_result.py
# #               tail -f /dev/null
# #           resources:
# #             limits:
# #               nvidia.com/gpu: 1  # Limit 1 NVIDIA GPUs
# #               #cpu: "5000m"      # Limit 5 CPUs
# #              # memory: "128Gi"    # Limit 128 GiB memory
# #             requests:
# #               nvidia.com/gpu: 1  # Request 1 NVIDIA GPUs
# #               #cpu: "5000m"      # Request 5 CPUs
# #              # memory: "128Gi"    # Request 128 GiB memory
# #      nodeSelector:
# #        topology.kubernetes.io/zone: "meyer"
# #       tolerations:
# #         - key: nvidia.com/gpu
# #           operator: Exists
# #           effect: NoSchedule
# #   backoffLimit: 0
# apiVersion: batch/v1
# kind: Job
# metadata:
#   name: fiola-init-job
# spec:
#   template:
#     spec:
#       restartPolicy: Never
#       containers:
#         - name: fiola-init-container
#           image: registry.hsrn.nyu.edu/vip/corelink-examples/fiola-init:latest
#           command: ["sh", "-c"]
#           args:
#             - |
#               export PYTHONPATH=/usr/src/app/FIOLA:/usr/src/app/CaImAn:/usr/local/lib/python3.8/dist-packages:${PYTHONPATH}
#               python3.8 ./generate_init_result.py
#               tail -f /dev/null
#           resources:
#             limits:
#               nvidia.com/gpu: 1  # Limit 1 NVIDIA GPUs
#             requests:
#               nvidia.com/gpu: 1  # Request 1 NVIDIA GPUs
#       nodeSelector:
#         topology.kubernetes.io/zone: "wwh"
#       tolerations:
#         - key: nvidia.com/gpu
#           operator: Exists
#           effect: NoSchedule
#   backoffLimit: 0
apiVersion: batch/v1
kind: Job
metadata:
  name: fiola-init-job
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: fiola-init-container
          image: registry.hsrn.nyu.edu/vip/corelink-examples/fiola-init:latest
          command: ["sh", "-c"]
          args:
            - |
              export PYTHONPATH=/usr/src/app/FIOLA:/usr/src/app/CaImAn:/usr/local/lib/python3.8/dist-packages:${PYTHONPATH}
              python3.8 ./generate_init_result.py
              tail -f /dev/null
          resources:
            limits:
              nvidia.com/gpu: 1  # Limit 1 NVIDIA GPUs
              cpu: "16"          # Limit 16 CPUs
              memory: "100Gi"    # Limit 100Gi memory
            # requests:
            #   nvidia.com/gpu: 1  # Request 1 NVIDIA GPUs
            #   cpu: "8"           # Request 8 CPUs
            #   memory: "50Gi"     # Request 50Gi memory
          env:
            - name: TF_FORCE_GPU_ALLOW_GROWTH
              value: "true"
            - name: TF_GPU_THREAD_MODE
              value: "gpu_private"
      nodeSelector:
        topology.kubernetes.io/zone: "wwh"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
  backoffLimit: 0
