# apiVersion: v1
# kind: PersistentVolumeClaim
# metadata:
#   name: profile-pvc
# spec:
#   accessModes:
#     - ReadWriteOnce
#   resources:
#     requests:
#       storage: 1Gi
# ---
# apiVersion: batch/v1
# kind: Job
# metadata:
#   name: fiola-process-job
# spec:
#   template:
#     spec:
#       restartPolicy: Never
#       containers:
#         - name: fiola-init-container
#           image: registry.hsrn.nyu.edu/vip/corelink-examples/fiola-process-cp2:latest
#           command: ["sh", "-c"]
#           args:
#             - |
#               python ./receive_then_fiola.py
#               tail -f /dev/null
#           resources:
#             limits:
#               nvidia.com/gpu: 1  # Limit 1 NVIDIA GPUs
#               cpu: "3000m"      # Limit 5 CPUs
#               memory: "128Gi"    # Limit 128 GiB memory
#             requests:
#               nvidia.com/gpu: 1  # Request 1 NVIDIA GPUs
#               cpu: "3000m"      # Request 5 CPUs
#               memory: "128Gi"    # Request 128 GiB memory
#           volumeMounts:
#             - name: profile-volume
#               mountPath: /usr/src/app/profile_data
#       volumes:
#         - name: profile-volume
#           persistentVolumeClaim:
#             claimName: profile-pvc
#       nodeSelector:
#         topology.kubernetes.io/zone: "12wvpl"
#         # topology.kubernetes.io/zone: "meyer"
#       tolerations:
#         - key: nvidia.com/gpu
#           operator: Exists
#           effect: NoSchedule
#   backoffLimit: 0
apiVersion: batch/v1
kind: Job
metadata:
  name: fiola-process-job1
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: fiola-init-container
          image: registry.hsrn.nyu.edu/vip/corelink-examples/fiola-process-cp:latest
          command: ["sh", "-c"]
          args:
            - |
              python ./receive_then_fiola.py
              tail -f /dev/null
          resources:
            limits:
              # nvidia.com/gpu: 1
              cpu: "3000m"
              memory: "128Gi"
            requests:
              # nvidia.com/gpu: 1
              cpu: "3000m"
              memory: "128Gi"
          volumeMounts:
            - name: profile-volume
              mountPath: /usr/src/app/profile_data
      volumes:
        - name: profile-volume
          persistentVolumeClaim:
            claimName: profile-pvc
      nodeSelector:
        topology.kubernetes.io/zone: "12wvpl"
      tolerations:
        # - key: nvidia.com/gpu
        #   operator: Exists
        #   effect: NoSchedule
  backoffLimit: 0
